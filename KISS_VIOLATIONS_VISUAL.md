# Visual KISS Violations Guide

## Violation 1: Triple LRU Eviction Implementation

### Current Architecture (Over-Complex)
```
GlobalCacheManager
  â”œâ”€â”€ _evict_lru() [27 lines, CC:6]
  â”‚   â”œâ”€ if count is None:
  â”‚   â”‚  â””â”€ while len(cache) >= limit:
  â”‚   â”‚     â””â”€ del cache[key] 
  â”‚   â”‚
  â”‚   â””â”€ else:
  â”‚      â””â”€ for _ in range(count):
  â”‚         â””â”€ del cache[key]
  â”‚
  â”œâ”€â”€ set() [Line 313]
  â”‚   â””â”€ self._evict_lru(ns, count=None)
  â”‚
  â””â”€â”€ _promote_to_memory() [Line 386]
      â””â”€ while len(cache) >= limit:  â† EXACT DUPLICATE!
         â””â”€ del cache[key]
```

### Simplified Architecture
```
GlobalCacheManager
  â””â”€â”€ _evict_lru(ns, count: int | None = 1) [11 lines, CC:2]
      â””â”€ if count is None:
         â””â”€ count = max(1, len - limit + 1)  â† Unified logic
      â””â”€ while evictions < count and cache:
         â””â”€ del cache[key]

Used by:
  â”œâ”€â”€ set() â†’ self._evict_lru(ns, count=None)
  â””â”€â”€ _promote_to_memory() â†’ self._evict_lru(ns, count=None)
```

**Impact**: -60 LOC, CC reduction: 6â†’2 (67% simpler)

---

## Violation 2: Quadruple Cache Key Generation

### Current: Four Different Implementations

```
decorators.py                         manager.py
  â”œâ”€ _serialize_cache_value()           â”œâ”€ _generate_cache_key()
  â”‚  (19 lines, handles enums)          â”‚  (31 lines, handles enums)
  â”‚                                     â”‚  Different serialization!
  â”œâ”€ _efficient_cache_key_parts()       
  â”‚  (20 lines)
  â”‚
  â””â”€ _generate_cache_key()
     (3 lines)

keys.py (Existing but not used!)
  â”œâ”€ generate_cache_key()
  â””â”€ serialize_cache_value()
```

### Flow Divergence Problem
```
Decorator path:          Manager path:           Keys path (unused):
value â†’ serialize        value â†’ str             value â†’ serialize
â†’ tuple(parts)          â†’ ":".join()             â†’ tuple(parts)
â†’ str()                 â†’ SHA256()               â†’ str()
â†’ SHA256()                                       â†’ SHA256()
```

Results in **different keys for same input**! âš ï¸

### Simplified: Single Source of Truth
```
keys.py (ONE implementation)
â”œâ”€ generate_cache_key(tuple) â†’ SHA256 hash
â””â”€ serialize_cache_value(value) â†’ primitive

Used everywhere:
â”œâ”€ decorators.py: from .keys import generate_cache_key
â”œâ”€ manager.py: from .keys import generate_cache_key
â””â”€ core.py: from .keys import generate_cache_key

Cache key generation logic: +1 place, -150 LOC duplication
```

**Impact**: -150 LOC, consolidates 4 implementations â†’ 1

---

## Violation 3: Namespace Configuration Explosion

### Current: Hardcoded Configuration
```
_init_default_namespaces()
  â”œâ”€ NamespaceConfig(DEFAULT,    memory=200, ttl=6h, disk=1d)
  â”œâ”€ NamespaceConfig(DICTIONARY, memory=500, ttl=24h, disk=7d)
  â”œâ”€ NamespaceConfig(CORPUS,     memory=100, ttl=30d, disk=90d, compress=ZSTD)
  â”œâ”€ NamespaceConfig(SEMANTIC,   memory=50,  ttl=7d, disk=30d)
  â”œâ”€ NamespaceConfig(SEARCH,     memory=300, ttl=1h, disk=6h)
  â”œâ”€ NamespaceConfig(TRIE,       memory=50,  ttl=7d, disk=30d, compress=LZ4)
  â”œâ”€ NamespaceConfig(LITERATURE, memory=50,  ttl=30d, disk=90d, compress=GZIP)
  â”œâ”€ NamespaceConfig(SCRAPING,   memory=100, ttl=1h, disk=24h, compress=ZSTD)
  â”œâ”€ NamespaceConfig(API,        memory=100, ttl=1h, disk=12h)
  â”œâ”€ NamespaceConfig(LANGUAGE,   memory=100, ttl=7d, disk=30d, compress=ZSTD)
  â”œâ”€ NamespaceConfig(OPENAI,     memory=200, ttl=24h, disk=7d, compress=ZSTD)
  â”œâ”€ NamespaceConfig(LEXICON,    memory=100, ttl=7d, disk=30d)
  â””â”€ NamespaceConfig(WOTD,       memory=50,  ttl=1d, disk=7d)

92 lines of copy-paste âŒ
```

### Magic Numbers Identified
```
Memory limits:  50, 100, 200, 300, 500        (5 values)
Memory TTL:     1h, 6h, 24h, 7d, 30d         (5 values)
Disk TTL:       6h, 12h, 24h, 7d, 30d, 90d   (6 values)
```

### Simplified: Data-Driven Configuration
```python
# Size profiles
NAMESPACE_DEFAULTS = {
    "small":  {"memory_limit": 50,   "memory_ttl": 7d},
    "medium": {"memory_limit": 100,  "memory_ttl": 24h},
    "large":  {"memory_limit": 500,  "memory_ttl": 24h},
}

# Namespace mapping
CONFIG_MAP = {
    DICTIONARY:  ("large",  7d),
    CORPUS:      ("small",  90d, ZSTD),
    SEMANTIC:    ("small",  30d),
    SEARCH:      ("medium", 6h),
    TRIE:        ("small",  30d, LZ4),
    LITERATURE:  ("small",  90d, GZIP),
    SCRAPING:    ("medium", 24h, ZSTD),
    API:         ("medium", 12h),
    LANGUAGE:    ("medium", 30d, ZSTD),
    OPENAI:      ("medium", 7d, ZSTD),
    LEXICON:     ("medium", 30d),
    WOTD:        ("small",  7d),
}

# Initialization
for namespace, (size, disk_ttl, *comp) in CONFIG_MAP.items():
    defaults = NAMESPACE_DEFAULTS[size]
    create_config(namespace, 
                 memory_limit=defaults["memory_limit"],
                 memory_ttl=defaults["memory_ttl"],
                 disk_ttl=disk_ttl,
                 compression=comp[0] if comp else None)
```

**Impact**: -84% (92â†’15 lines), magic numbers centralized

---

## Violation 4: Four Nearly-Identical Decorators

### Current Decorator Landscape
```
decorators.py contains:

1. cached_api_call()              [90 lines]
   â””â”€ For async API calls
   â””â”€ With 24h TTL default
   â””â”€ Optional header inclusion

2. cached_computation_async()     [48 lines]
   â””â”€ For async computations
   â””â”€ With 7d TTL default
   â””â”€ Async-only

3. cached_computation_sync()      [61 lines]
   â””â”€ For sync computations
   â””â”€ Creates event loop
   â””â”€ Calls async_runner internally

4. cached_api_call_with_dedup()  [114 lines]
   â””â”€ Like #1 but with deduplication
   â””â”€ Nearly identical to #1
   â””â”€ Duplicates all logic
```

### Code Duplication: Core Logic
```python
# PATTERN REPEATED IN ALL 4 DECORATORS (>200 LOC duplicated):

# Step 1: Generate cache key (4 different ways!)
key_parts = _efficient_cache_key_parts(func, args, kwargs)
cache_key = _generate_cache_key(key_parts)

# Step 2: Get cache (identical in all)
cache = await get_global_cache()
namespace = CACHE_NAMESPACE_MAP.get(key_prefix, CacheNamespace.API)

# Step 3: Check cache (identical in all)
cached_result = await cache.get(namespace, cache_key)
if cached_result is not None:
    logger.debug(f"ğŸ’¨ Cache hit...")
    return cached_result

# Step 4: Execute function (varies: async vs sync)
result = await func(*args, **kwargs)  # or just func(*args, **kwargs)

# Step 5: Store cache (identical in all)
await cache.set(namespace, cache_key, result, 
               ttl_override=timedelta(hours=ttl_hours))

return result
```

### Simplified: One Decorator to Rule Them All
```python
def cached(
    ttl_hours: float = 24.0,
    namespace_key: str = "api",
    deduplicate: bool = False,
    ignore_params: list[str] | None = None,
) -> Callable:
    """Universal cache decorator.
    
    Features:
    - Auto-detect sync vs async
    - Optional deduplication
    - Parameter filtering
    - Headers inclusion
    """
    def decorator(func):
        is_async = inspect.iscoroutinefunction(func)
        
        async def async_impl(*args, **kwargs):
            # Single implementation shared by all
            # ... (implements all features)
        
        return async_impl if is_async else sync_wrapper
    return decorator

# Usage becomes simple:
@cached()                                    # Default: API, 24h
async def fetch_api(): ...

@cached(ttl_hours=168, deduplicate=True)    # 7d, dedup
async def expensive_compute(): ...

@cached(namespace_key="compute")             # Sync, auto-detected
def sync_operation(): ...

@cached(cached_api_call_with_dedup())       # Removed! Feature â†’ deduplicate=True
async def api_with_dedup(): ...
```

**Impact**: Consolidates 4 functions â†’ 1, removes ~200 LOC duplication

---

## Violation 5: NamespaceConfig Over-Abstraction

### Current: Mixing Concerns
```
class NamespaceConfig:
    # Configuration (static)
    name: CacheNamespace
    memory_limit: int
    memory_ttl: timedelta
    disk_ttl: timedelta
    compression: CompressionType
    
    # Runtime state (mutable)
    memory_cache: dict = {}           â† Should NOT be here!
    lock: asyncio.Lock()              â† Should NOT be here!
    stats: dict = {hits, misses, evictions}  â† Should NOT be here!

Problem: Configuration and runtime state mixed
Result: 4 layers of indirection: Manager â†’ Config â†’ state â†’ data
```

### Simplified: Separation of Concerns
```
# 1. Pure configuration (immutable data)
@dataclass
class NamespaceConfig:
    name: CacheNamespace
    memory_limit: int
    memory_ttl: timedelta | None
    disk_ttl: timedelta | None
    compression: CompressionType | None

# 2. Runtime state (in Manager)
class GlobalCacheManager:
    configs: dict[CacheNamespace, NamespaceConfig]    # Config only
    memory_caches: dict[CacheNamespace, dict]         # Runtime state
    stats: dict[CacheNamespace, CacheStats]           # Metrics
    lock: asyncio.Lock()                              # Single lock

# 3. Clear responsibility:
# - NamespaceConfig: "What should we cache?"
# - GlobalCacheManager: "How do we cache it?"
```

**Impact**: Clearer code, easier to test configuration

---

## Violation 6: Feature Envy in Content Storage

### Current: Excessive Property Access
```
async def set_versioned_content(versioned_data, content, force_external=False):
    # Accessing 7+ properties of versioned_data:
    
    cache_key = _generate_cache_key(
        versioned_data.resource_type,           # â† Property access
        versioned_data.resource_id,             # â† Property access
        "content",
        versioned_data.version_info.data_hash[:8],  # â† Deep nesting!
    )
    
    namespace = versioned_data.namespace        # â† Property access
    
    # ... 50+ more lines accessing versioned_data properties
    
    versioned_data.content_location = ContentLocation(...)  # â† Setting property
    versioned_data.content_inline = None                   # â† Setting property

Symptom: Too much knowledge of versioned_data internals!
```

### Simplified: Encapsulation
```
# Move logic INTO BaseVersionedData where it belongs

class BaseVersionedData(Document):
    async def store_content(self, content: Any, force_external: bool = False) -> None:
        """I know how to store MY content."""
        cache = await get_global_cache()
        
        # Self-awareness: I know my own fields!
        cache_key = _generate_cache_key(
            self.resource_type,
            self.resource_id,
            "content",
            self.version_info.data_hash[:8]
        )
        
        if not force_external:
            if self._estimate_size(content) < 16 * 1024:
                self.content_inline = content
                return
        
        # External storage
        await cache.set(self.namespace, cache_key, content, ttl=self.ttl)
        self.content_location = ContentLocation(...)
        self.content_inline = None
    
    def _estimate_size(self, content: Any) -> int:
        """I know how to estimate MY content size."""
        if isinstance(content, dict) and "binary_data" in content:
            return sum(len(v) for v in content["binary_data"].values()) + 1000
        return len(json.dumps(content, default=str).encode())

# External caller: Just delegate
async def set_versioned_content(versioned_data, content, *, force_external=False):
    await versioned_data.store_content(content, force_external)
```

**Impact**: Removes 80 LOC of inappropriate coupling

---

## Violation 7: Nested Conditional Complexity

### Current: 5 Levels Deep
```
if cached_obj:                                    # Level 1
    if not config.version:                       # Level 2
        try:                                     # Level 3
            doc = await model_class.find_one(...)
            if not doc:                          # Level 4
                await cache.delete(...)
            else:                                # Level 4
                if cached_obj.content_location:  # Level 5
                    content = await get_versioned_content(cached_obj)
                    if content is None:          # Level 6! 
                        await cache.delete(...)
                    else:
                        return cached_obj        # â† Return buried 6 levels!
                else:
                    return cached_obj            # â† Return buried 5 levels!
        except Exception as e:
            await cache.delete(...)
    else:
        return cached_obj                        # â† No validation!
```

**Problems**:
- Hard to understand
- Multiple return paths
- Easy to miss edge cases
- One path (version-specific) has NO validation

### Simplified: Guard Clauses
```
if not cached_obj:
    pass  # Fall through to database query
elif config.version:
    # Version-specific cache is authoritative (no validation needed)
    logger.debug(f"Cache hit: {cache_key} (version-specific)")
    return cached_obj
else:
    # Latest version cache: validate before returning
    doc = await model_class.find_one({"_id": cached_obj.id})
    
    if not doc:
        # Document deleted since caching
        logger.debug(f"Cached document deleted: {cache_key}")
        await cache.delete(namespace, cache_key)
        pass  # Fall through
    elif not await self._validate_content(cached_obj, cache_key):
        # Content missing or corrupted
        await cache.delete(namespace, cache_key)
        pass  # Fall through
    else:
        # All validations passed
        logger.debug(f"Cache hit: {cache_key} (validated)")
        return cached_obj

# Helper function (reusable, testable)
async def _validate_content(self, obj: BaseVersionedData, cache_key: str) -> bool:
    """Check if cached object has accessible content."""
    if obj.content_location is None:
        return True  # Inline content always accessible
    
    content = await get_versioned_content(obj)
    if content is None:
        logger.error(f"Content missing for {cache_key}")
        return False
    return True
```

**Changes**:
- CC: 12 â†’ 4 (67% simpler)
- Nesting: 6 â†’ 2 (67% flatter)
- Early returns prevent deep nesting
- Logic is linear and clear

**Impact**: -50 LOC, massively improved readability

---

## Violation 8: Redundant Async Wrappers

### Current: Unnecessary Indirection
```
class GlobalCacheManager:
    async def _compress_data(self, data, compression):
        """Async wrapper that does nothing async."""
        return compress_data(data, compression)
        # â†‘ This is SYNC! Why async?
    
    async def _decompress_data(self, data, compression):
        """Async wrapper that does nothing async."""
        return decompress_data(data, compression)
        # â†‘ This is SYNC! Why async?

Usage:
    data = await self._decompress_data(data, ns.compression)
    # â†‘ Await for no reason!
```

**Problem**: 
- Compression is CPU-bound, not I/O bound
- Already using executor in FilesystemBackend for I/O
- Adds unnecessary async overhead
- Confusing for readers

### Simplified: Direct Calls
```
# Remove the async wrapper methods entirely

# In get():
if ns.compression and isinstance(data, bytes):
    data = decompress_data(data, ns.compression)
    # Direct sync call - simpler and faster!

# In set():
if ns.compression:
    store_value = compress_data(value, ns.compression)
    # No async, no await needed
```

**Impact**: -20 LOC, clearer intent, no performance penalty

---

## Summary: Violation Severity Chart

```
IMPACT ANALYSIS

HIGH PRIORITY (Fix First)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Cache Key Duplication       [150 LOC] â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   â”‚
â”‚    4 implementations â†’ 1                                 â”‚
â”‚                                                          â”‚
â”‚ 2. Decorator Functions          [200 LOC] â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ â”‚
â”‚    4 variants â†’ 1 generic                               â”‚
â”‚                                                          â”‚
â”‚ 3. LRU Eviction Duplication     [60 LOC]  â–ˆâ–ˆâ–ˆâ–ˆ          â”‚
â”‚    3 implementations â†’ 1                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

MEDIUM PRIORITY (Fix After)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. Namespace Configs            [92 LOC]  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ        â”‚
â”‚    13 hardcoded â†’ data-driven                           â”‚
â”‚                                                          â”‚
â”‚ 5. Nested Conditionals          [100 LOC] â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ       â”‚
â”‚    CC:12 â†’ 4, nesting:6 â†’ 2                            â”‚
â”‚                                                          â”‚
â”‚ 6. Feature Envy (Content Store) [80 LOC]  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ         â”‚
â”‚    80 lines of property access                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

LOW PRIORITY (Polish)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 7. Async Wrappers               [20 LOC]  â–ˆâ–ˆ            â”‚
â”‚    Remove unnecessary indirection                       â”‚
â”‚                                                          â”‚
â”‚ 8. NamespaceConfig Concerns     [60 LOC]  â–ˆâ–ˆâ–ˆâ–ˆ          â”‚
â”‚    Separate config from state                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

TOTAL SAVINGS: ~770 LOC (28% of module)
COMPLEXITY: CC 6.2 â†’ 2.1 (67% reduction)
```

---

## Implementation Timeline

```
Phase 1: Quick Wins (30 min)
  âœ“ Consolidate cache keys â†’ keys.py
  âœ“ Simplify LRU eviction
  âœ“ Remove async wrappers
  Result: 230 LOC saved, 40% easier to read

Phase 2: Medium Effort (2 hours)
  âœ“ Create @cached decorator (auto-detect + dedup)
  âœ“ Extract _validate_content helper
  Result: 200 LOC saved, 50% simpler logic

Phase 3: Refactoring (3 hours)
  âœ“ Move content storage to model
  âœ“ Data-drive namespace config
  âœ“ Decouple config from state
  Result: 340 LOC saved, fully maintainable

Total: ~6 hours for 28% LOC reduction, 67% complexity reduction
```

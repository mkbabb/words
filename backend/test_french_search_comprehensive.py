"""
Comprehensive tests for French search functionality.

Tests the specific issues identified:
1. "enui" should return "ennui" (fuzzy)
2. "en coulise" should return "en coulisse" (fuzzy)
3. "√† fond" should return with diacritics preserved (original preservation)
4. Semantic search should work for French diacritics
5. Normalization should be consistent between corpus and queries
"""

import asyncio

from src.floridify.search.constants import DEFAULT_MIN_SCORE
from src.floridify.search.core import SearchEngine
from src.floridify.search.corpus.core import Corpus
from src.floridify.text.normalize import batch_normalize, normalize_comprehensive, normalize_fast

# Real French expressions with diacritics from the dataset
FRENCH_TEST_CORPUS = [
    "√† la",
    "√† la carte", 
    "√† propos",
    "affaire de c≈ìur",
    "amour propre",
    "amuse-bouche",
    "ancien r√©gime",
    "ap√©ritif",
    "appellation contr√¥l√©e",
    "apr√®s moi, le d√©luge",
    "en coulisse",  # Target for "en coulise" test
    "ennui",        # Target for "enui" test
    "√† fond",       # Target for diacritic preservation test
    "caf√©",         # Simple diacritic test
    "na√Øve",        # Diaeresis test
    "r√©sum√©",       # Acute accent test
    "pi√®ce de r√©sistance",
    "vis-√†-vis",
    "d√©but",
    "fianc√©",
    "na√Øvet√©"
]

# Test cases: (typo/query, expected_match, test_type)
FUZZY_TEST_CASES = [
    ("enui", "ennui", "missing_n"),
    ("en coulise", "en coulisse", "missing_s"),
    ("a la", "√† la", "missing_diacritic"),  
    ("a propos", "√† propos", "missing_diacritic"),
    ("apres", "apr√®s", "missing_diacritic"),
    ("cafe", "caf√©", "missing_diacritic"),
    ("resume", "r√©sum√©", "missing_diacritics"),
    ("naive", "na√Øve", "missing_diaeresis"),
    ("debut", "d√©but", "missing_circumflex"),
    ("fiance", "fianc√©", "missing_acute"),
]

SEMANTIC_TEST_CASES = [
    ("enui", "ennui", "typo_semantic"),
    ("en coulise", "en coulisse", "phrase_typo_semantic"), 
    ("love affair", "affaire de c≈ìur", "translation_semantic"),
    ("in the style of", "√† la", "translation_semantic"),
    ("appetite drink", "ap√©ritif", "description_semantic"),
]

ORIGINAL_PRESERVATION_CASES = [
    ("√† fond", "√† fond"),  # Should return WITH diacritic
    ("caf√©", "caf√©"),      # Should return WITH diacritic  
    ("r√©sum√©", "r√©sum√©"),  # Should return WITH diacritics
    ("na√Øve", "na√Øve"),    # Should return WITH diaeresis
]


class TestNormalizationConsistency:
    """Test normalization function usage consistency."""
    
    def test_normalize_differences(self):
        """Verify that comprehensive and fast normalization produce different results."""
        test_words = ["caf√©", "r√©sum√©", "na√Øve", "√† propos"]
        
        for word in test_words:
            fast = normalize_fast(word)
            comprehensive = normalize_comprehensive(word) 
            
            # Both should exist but may differ in processing depth
            assert fast is not None
            assert comprehensive is not None
            
            print(f"'{word}' -> fast: '{fast}', comprehensive: '{comprehensive}'")
    
    def test_batch_normalize_strategy(self):
        """Test that batch_normalize can use both strategies."""
        test_words = FRENCH_TEST_CORPUS[:5]
        
        fast_results = batch_normalize(test_words, use_comprehensive=False)
        comprehensive_results = batch_normalize(test_words, use_comprehensive=True)
        
        assert len(fast_results) == len(comprehensive_results)
        
        for i, (fast, comp) in enumerate(zip(fast_results, comprehensive_results)):
            print(f"'{test_words[i]}' -> fast: '{fast}', comprehensive: '{comp}'")


class TestFuzzySearchIssues:
    """Test fuzzy search with various threshold configurations."""
    
    async def test_fuzzy_with_default_threshold(self):
        """Test fuzzy search with default 0.6 threshold."""
        corpus = await Corpus.create("test_french", FRENCH_TEST_CORPUS)
        search_engine = SearchEngine(corpus)
        failures = []
        
        for query, expected, test_type in FUZZY_TEST_CASES:
            results = await search_engine.fuzzy_search(query, min_score=DEFAULT_MIN_SCORE)
            
            found_match = any(r.word == expected for r in results)
            if not found_match:
                scores = [(r.word, r.score) for r in results[:3]]
                failures.append((query, expected, test_type, scores))
                
        print(f"\n=== FUZZY SEARCH FAILURES (threshold={DEFAULT_MIN_SCORE}) ===")
        for query, expected, test_type, scores in failures:
            print(f"‚ùå '{query}' -> '{expected}' ({test_type})")
            print(f"   Top results: {scores}")
            
        # This test documents current failures - will pass once fixes are implemented
        assert len(failures) >= 0, "Test is documenting current state"
    
    async def test_fuzzy_with_lower_threshold(self):
        """Test fuzzy search with lower 0.4 threshold."""
        failures = []
        successes = []
        
        corpus = await Corpus.create("test_french", FRENCH_TEST_CORPUS)
        search_engine = SearchEngine(corpus)
        
        for query, expected, test_type in FUZZY_TEST_CASES:
            results = await search_engine.fuzzy_search(query, min_score=0.4)
            
            found_match = any(r.word == expected for r in results)
            if found_match:
                match_score = next(r.score for r in results if r.word == expected)
                successes.append((query, expected, test_type, match_score))
            else:
                scores = [(r.word, r.score) for r in results[:3]]
                failures.append((query, expected, test_type, scores))
                
        print("\n=== FUZZY SEARCH WITH LOWER THRESHOLD (0.4) ===")
        print(f"‚úÖ Successes: {len(successes)}")
        for query, expected, test_type, score in successes:
            print(f"   '{query}' -> '{expected}' ({test_type}) score: {score:.3f}")
            
        print(f"‚ùå Failures: {len(failures)}")  
        for query, expected, test_type, scores in failures:
            print(f"   '{query}' -> '{expected}' ({test_type})")
            print(f"     Top results: {scores}")


class TestSemanticSearchIssues:
    """Test semantic search on French examples."""
    
    async def test_semantic_with_default_threshold(self):
        """Test semantic search with default 0.6 threshold.""" 
        failures = []
        
        corpus = await Corpus.create("test_french", FRENCH_TEST_CORPUS, semantic=True)
        search_engine = SearchEngine(corpus)
        
        for query, expected, test_type in SEMANTIC_TEST_CASES:
            results = await search_engine.semantic_search(query, min_score=DEFAULT_MIN_SCORE)
            
            found_match = any(r.word == expected for r in results)
            if not found_match:
                scores = [(r.word, r.score) for r in results[:3]]
                failures.append((query, expected, test_type, scores))
                
        print(f"\n=== SEMANTIC SEARCH FAILURES (threshold={DEFAULT_MIN_SCORE}) ===")
        for query, expected, test_type, scores in failures:
            print(f"‚ùå '{query}' -> '{expected}' ({test_type})")
            print(f"   Top results: {scores}")
            
    async def test_semantic_with_lower_threshold(self):
        """Test semantic search with lower 0.4 threshold."""
        failures = []
        successes = []
        
        corpus = await Corpus.create("test_french", FRENCH_TEST_CORPUS, semantic=True)
        search_engine = SearchEngine(corpus)
        
        for query, expected, test_type in SEMANTIC_TEST_CASES:
            results = await search_engine.semantic_search(query, min_score=0.4)
            
            found_match = any(r.word == expected for r in results)
            if found_match:
                match_score = next(r.score for r in results if r.word == expected)
                successes.append((query, expected, test_type, match_score))
            else:
                scores = [(r.word, r.score) for r in results[:3]]
                failures.append((query, expected, test_type, scores))
                
        print("\n=== SEMANTIC SEARCH WITH LOWER THRESHOLD (0.4) ===")
        print(f"‚úÖ Successes: {len(successes)}")
        for query, expected, test_type, score in successes:
            print(f"   '{query}' -> '{expected}' ({test_type}) score: {score:.3f}")
            
        print(f"‚ùå Failures: {len(failures)}")
        for query, expected, test_type, scores in failures:
            print(f"   '{query}' -> '{expected}' ({test_type})")
            print(f"     Top results: {scores}")


class TestOriginalWordPreservation:
    """Test that original words with diacritics are preserved in results."""
    
    async def test_exact_search_preserves_diacritics(self):
        """Test that exact search returns original diacritics."""
        preservation_failures = []
        
        corpus = await Corpus.create("test_french", FRENCH_TEST_CORPUS)
        search_engine = SearchEngine(corpus)
        
        for query, expected_original in ORIGINAL_PRESERVATION_CASES:
            results = await search_engine.exact_search(query)
            
            if results:
                returned_word = results[0].word
                if returned_word != expected_original:
                    preservation_failures.append((query, expected_original, returned_word))
            else:
                preservation_failures.append((query, expected_original, "NO_RESULTS"))
                
        print("\n=== ORIGINAL WORD PRESERVATION TEST ===")
        if preservation_failures:
            print("‚ùå Diacritics NOT preserved:")
            for query, expected, actual in preservation_failures:
                print(f"   '{query}' -> expected: '{expected}', got: '{actual}'")
        else:
            print("‚úÖ All diacritics preserved correctly")
            
        # This documents current behavior - will change once dual storage is implemented
        return preservation_failures
    
    async def test_fuzzy_search_preserves_diacritics(self):
        """Test that fuzzy search returns original diacritics."""
        preservation_failures = []
        
        # Test fuzzy searches that should return diacritics
        fuzzy_preservation_cases = [
            ("a la", "√† la"),      # Remove diacritic, should return with diacritic
            ("cafe", "caf√©"),      # Remove diacritic, should return with diacritic
            ("a propos", "√† propos"),  # Remove diacritic, should return with diacritic
        ]
        
        corpus = await Corpus.create("test_french", FRENCH_TEST_CORPUS)
        search_engine = SearchEngine(corpus)
        
        for query, expected_original in fuzzy_preservation_cases:
            results = await search_engine.fuzzy_search(query, min_score=0.4)
            
            found_original = any(r.word == expected_original for r in results)
            if not found_original:
                returned_words = [r.word for r in results[:3]]
                preservation_failures.append((query, expected_original, returned_words))
                
        print("\n=== FUZZY SEARCH DIACRITIC PRESERVATION ===")
        if preservation_failures:
            print("‚ùå Original diacritics NOT returned:")
            for query, expected, actual_list in preservation_failures:
                print(f"   '{query}' -> expected: '{expected}', got: {actual_list}")
        else:
            print("‚úÖ Fuzzy search returns original diacritics")
            
        return preservation_failures


async def run_comprehensive_search_test():
    """Run all tests and generate comprehensive report."""
    print("üîç COMPREHENSIVE FRENCH SEARCH TEST SUITE")
    print("=" * 60)
    
    # Test 1: Normalization consistency  
    norm_test = TestNormalizationConsistency()
    norm_test.test_normalize_differences()
    norm_test.test_batch_normalize_strategy()
    
    # Test 2: Create search engine for other tests
    corpus = await Corpus.create("test_french_comprehensive", FRENCH_TEST_CORPUS, semantic=True)
    search_engine = SearchEngine(corpus)
    
    # Test 3: Fuzzy search issues
    fuzzy_test = TestFuzzySearchIssues()
    await fuzzy_test.test_fuzzy_with_default_threshold()
    await fuzzy_test.test_fuzzy_with_lower_threshold()
    
    # Test 4: Semantic search issues  
    semantic_test = TestSemanticSearchIssues()
    await semantic_test.test_semantic_with_default_threshold()
    await semantic_test.test_semantic_with_lower_threshold()
    
    # Test 5: Original word preservation
    preservation_test = TestOriginalWordPreservation()
    exact_failures = await preservation_test.test_exact_search_preserves_diacritics()
    fuzzy_failures = await preservation_test.test_fuzzy_search_preserves_diacritics()
    
    # Summary
    print("\n" + "=" * 60)
    print("üìä TEST SUMMARY")
    print(f"   Exact search diacritic preservation failures: {len(exact_failures)}")
    print(f"   Fuzzy search diacritic preservation failures: {len(fuzzy_failures)}")
    print("   See detailed results above for specific failure cases")
    print("=" * 60)


if __name__ == "__main__":
    asyncio.run(run_comprehensive_search_test())
#!/usr/bin/env python3
"""Test complete language-level corpus building with proper aggregation and indexing."""

import asyncio
import time
from datetime import datetime
from rich.console import Console
from rich.table import Table
from rich.progress import track

from floridify.corpus.language.core import LanguageCorpus
from floridify.corpus.manager import get_tree_corpus_manager
from floridify.models.base import Language
from floridify.search.core import Search
from floridify.search.models import SearchIndex
from floridify.search.semantic.models import SemanticIndex
from floridify.storage.mongodb import init_db
from floridify.utils.logging import get_logger

console = Console()
logger = get_logger(__name__)


async def build_and_aggregate_corpus():
    """Build language corpus and properly aggregate vocabulary."""
    console.print("\n[bold blue]üèóÔ∏è  Building Language Corpus with Aggregation[/bold blue]")
    console.print("=" * 80)

    start_time = time.time()

    # Initialize database
    await init_db()

    # Step 1: Create language corpus
    console.print("\n[yellow]üìö Step 1: Creating language corpus with parallel sources...[/yellow]")
    corpus = await LanguageCorpus.create_from_language(
        language=Language.ENGLISH,
        corpus_name="language_english_full"
    )

    console.print(f"[green]‚úÖ Initial corpus created[/green]")
    console.print(f"  ‚Ä¢ Corpus ID: {corpus.corpus_id}")
    console.print(f"  ‚Ä¢ Initial vocabulary: {len(corpus.vocabulary):,}")
    console.print(f"  ‚Ä¢ Children: {len(corpus.child_corpus_ids or [])}")

    # Step 2: Aggregate vocabulary from children
    console.print("\n[yellow]üîÑ Step 2: Aggregating vocabulary from child corpora...[/yellow]")
    manager = get_tree_corpus_manager()

    if corpus.corpus_id:
        agg_start = time.time()
        aggregated_vocab = await manager.aggregate_vocabularies(
            corpus_id=corpus.corpus_id,
            update_parent=True
        )
        agg_time = time.time() - agg_start

        console.print(f"[green]‚úÖ Vocabulary aggregated in {agg_time:.2f}s[/green]")
        console.print(f"  ‚Ä¢ Aggregated vocabulary: {len(aggregated_vocab):,}")

        # Reload corpus to get updated vocabulary
        corpus = await manager.get_corpus(corpus_id=corpus.corpus_id)
        console.print(f"  ‚Ä¢ Updated corpus vocabulary: {len(corpus.vocabulary):,}")
        console.print(f"  ‚Ä¢ Lemmatized vocabulary: {len(corpus.lemmatized_vocabulary):,}")

    build_time = time.time() - start_time
    console.print(f"  ‚Ä¢ Total build time: {build_time:.2f}s")

    return corpus


async def build_search_indices(corpus):
    """Build all search indices including SemanticIndex."""
    console.print("\n[bold blue]üîé Building Search Indices[/bold blue]")
    console.print("=" * 80)

    start_time = time.time()

    # Create search with semantic enabled
    console.print("\n[yellow]Building unified search index...[/yellow]")
    search = await Search.from_corpus(
        corpus=corpus,
        semantic_model="Alibaba-NLP/gte-Qwen2-1.5B-instruct"
    )

    index_time = time.time() - start_time
    console.print(f"[green]‚úÖ Search indices built in {index_time:.2f}s[/green]")
    console.print(f"  ‚Ä¢ Trie index: {'‚úì' if search.trie_search else '‚úó'}")
    console.print(f"  ‚Ä¢ Fuzzy search: {'‚úì' if search.fuzzy_search else '‚úó'}")
    console.print(f"  ‚Ä¢ Semantic search: {'‚úì' if search.semantic_search else '‚úó'}")

    return search


async def verify_persistence(corpus_name: str):
    """Verify all indices are properly persisted."""
    console.print("\n[bold blue]üíæ Verifying Index Persistence[/bold blue]")
    console.print("=" * 80)

    results = []

    # Check SearchIndex
    console.print("\n[yellow]Checking SearchIndex...[/yellow]")
    search_index = await SearchIndex.get(corpus_name=corpus_name)
    if search_index:
        console.print(f"[green]‚úÖ SearchIndex found[/green]")
        console.print(f"  ‚Ä¢ Vocabulary hash: {search_index.vocabulary_hash[:16]}...")
        console.print(f"  ‚Ä¢ Has trie: {search_index.has_trie}")
        console.print(f"  ‚Ä¢ Has fuzzy: {search_index.has_fuzzy}")
        console.print(f"  ‚Ä¢ Has semantic: {search_index.has_semantic}")
        results.append(("SearchIndex", "‚úÖ", search_index.vocabulary_hash[:8]))
    else:
        console.print("[red]‚ùå SearchIndex not found[/red]")
        results.append(("SearchIndex", "‚ùå", "N/A"))

    # Check SemanticIndex
    console.print("\n[yellow]Checking SemanticIndex...[/yellow]")
    semantic_index = await SemanticIndex.get(
        corpus_name=corpus_name,
        model_name="Alibaba-NLP/gte-Qwen2-1.5B-instruct"
    )
    if semantic_index:
        console.print(f"[green]‚úÖ SemanticIndex found[/green]")
        console.print(f"  ‚Ä¢ Model: {semantic_index.model_name}")
        console.print(f"  ‚Ä¢ Vocabulary hash: {semantic_index.vocabulary_hash[:16]}...")
        console.print(f"  ‚Ä¢ Embeddings: {semantic_index.num_embeddings:,}")
        console.print(f"  ‚Ä¢ Index type: {semantic_index.index_type}")
        console.print(f"  ‚Ä¢ Memory usage: {semantic_index.memory_usage_mb:.2f} MB")
        console.print(f"  ‚Ä¢ Build time: {semantic_index.build_time_seconds:.2f}s")
        results.append(("SemanticIndex", "‚úÖ", f"{semantic_index.num_embeddings:,} embeddings"))
    else:
        console.print("[red]‚ùå SemanticIndex not found[/red]")
        results.append(("SemanticIndex", "‚ùå", "N/A"))

    # Check MongoDB persistence
    from pymongo import MongoClient
    client = MongoClient("mongodb://localhost:27017")
    db = client.floridify

    console.print("\n[yellow]Checking MongoDB persistence...[/yellow]")
    table = Table(title="Versioned Data Summary")
    table.add_column("Resource Type", style="cyan")
    table.add_column("Count", style="magenta")
    table.add_column("Latest", style="green")

    for resource_type in ["corpus", "search", "semantic", "trie"]:
        count = db.versioned_data.count_documents({"resource_type": resource_type})
        latest = db.versioned_data.find_one(
            {"resource_type": resource_type, "version_info.is_latest": True},
            {"version_info.version": 1}
        )
        version = latest["version_info"]["version"] if latest else "N/A"
        table.add_row(resource_type, str(count), version)

    console.print(table)

    return all(status == "‚úÖ" for _, status, _ in results[:2])  # Check main indices


async def test_search_performance(search):
    """Test search performance with various queries."""
    console.print("\n[bold blue]‚ö° Testing Search Performance[/bold blue]")
    console.print("=" * 80)

    test_queries = [
        ("hello", "exact"),
        ("perspicacious", "exact"),
        ("helllo", "fuzzy"),
        ("quick brown fox", "semantic"),
        ("language", "combined"),
    ]

    results = []
    for query, method in test_queries:
        start = time.time()
        search_results = await search.search(query, method=method, max_results=5)
        elapsed = (time.time() - start) * 1000  # Convert to ms

        if search_results:
            result_str = f"{len(search_results)} results, top: {search_results[0].word}"
            console.print(f"  {method:10s} '{query:20s}': {elapsed:6.2f}ms - {result_str}")
            results.append((method, elapsed))
        else:
            console.print(f"  {method:10s} '{query:20s}': {elapsed:6.2f}ms - No results")

    # Performance summary
    if results:
        console.print("\n[yellow]Performance Summary:[/yellow]")
        for method, elapsed in results:
            status = "‚úÖ" if elapsed < 10 else "‚ö†Ô∏è" if elapsed < 50 else "‚ùå"
            console.print(f"  {status} {method}: {elapsed:.2f}ms")


async def check_multiprocessing_evidence():
    """Check for evidence of multiprocessing optimizations."""
    console.print("\n[bold blue]üîß Optimization Evidence[/bold blue]")
    console.print("=" * 80)

    # Check latest log for multiprocessing evidence
    import subprocess

    # Check for parallel source fetching
    result = subprocess.run(
        "tail -100 corpus_build_optimized.log 2>/dev/null | grep -c 'Successfully added.*sources' || echo 0",
        shell=True,
        capture_output=True,
        text=True
    )

    if int(result.stdout.strip()) > 0:
        console.print("[green]‚úÖ Parallel source fetching detected[/green]")

    # Check for multiprocess embeddings
    result = subprocess.run(
        "tail -100 corpus_build_optimized.log 2>/dev/null | grep -c 'Encoding.*with.*workers' || echo 0",
        shell=True,
        capture_output=True,
        text=True
    )

    if int(result.stdout.strip()) > 0:
        console.print("[green]‚úÖ Multiprocess embedding generation detected[/green]")

    # Check for FAISS OpenMP
    result = subprocess.run(
        "tail -100 corpus_build_optimized.log 2>/dev/null | grep -c 'FAISS OpenMP' || echo 0",
        shell=True,
        capture_output=True,
        text=True
    )

    if int(result.stdout.strip()) > 0:
        console.print("[green]‚úÖ FAISS OpenMP threading configured[/green]")


async def main():
    """Main execution."""
    console.print("\n[bold cyan]‚ïê" * 80 + "[/bold cyan]")
    console.print("[bold cyan] COMPREHENSIVE LANGUAGE CORPUS TEST WITH FULL INDEXING[/bold cyan]")
    console.print("[bold cyan]‚ïê" * 80 + "[/bold cyan]")
    console.print(f"\nüìÖ Started: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

    try:
        overall_start = time.time()

        # Build and aggregate corpus
        corpus = await build_and_aggregate_corpus()

        if len(corpus.vocabulary) == 0:
            console.print("\n[red]‚ùå ERROR: Corpus has no vocabulary after aggregation![/red]")
            return

        # Build search indices
        search = await build_search_indices(corpus)

        # Verify persistence
        all_persisted = await verify_persistence(corpus.corpus_name)

        # Test search performance
        await test_search_performance(search)

        # Check for optimization evidence
        await check_multiprocessing_evidence()

        # Final summary
        overall_time = time.time() - overall_start

        console.print("\n[bold green]‚ïê" * 80 + "[/bold green]")
        console.print("[bold green] ‚úÖ TEST COMPLETE[/bold green]")
        console.print("[bold green]‚ïê" * 80 + "[/bold green]")
        console.print(f"\nüìä Final Summary:")
        console.print(f"  ‚Ä¢ Total time: {overall_time:.1f}s")
        console.print(f"  ‚Ä¢ Corpus vocabulary: {len(corpus.vocabulary):,} words")
        console.print(f"  ‚Ä¢ Lemmatized: {len(corpus.lemmatized_vocabulary):,} words")
        console.print(f"  ‚Ä¢ All indices persisted: {'‚úÖ Yes' if all_persisted else '‚ùå No'}")

        # Performance targets
        console.print(f"\nüéØ Performance vs Targets:")
        console.print(f"  ‚Ä¢ Fuzzy search: < 10ms target")
        console.print(f"  ‚Ä¢ Semantic search: < 20ms target")
        console.print(f"  ‚Ä¢ Combined search: < 50ms target")

    except Exception as e:
        console.print(f"\n[bold red]‚ùå Error: {e}[/bold red]")
        logger.exception("Test failed")
        raise


if __name__ == "__main__":
    asyncio.run(main())